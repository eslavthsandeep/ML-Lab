{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "43bbfd65-8708-46ce-b8cb-f6490143e809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Outlier Removal -> MSE: 0.011478378238310955 R²: 0.5615150232988959\n",
      "After Outlier Removal  -> MSE: 0.00740010503628017 R²: 0.3635936809174899\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# =========================\n",
    "#  Utility Functions\n",
    "# =========================\n",
    "\n",
    "def handle_missing_mean(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype != 'object':\n",
    "            df[col] = df[col].fillna(df[col].mean())\n",
    "    return df\n",
    "\n",
    "\n",
    "def min_max_scale(df):\n",
    "    scaled_df = df.copy()\n",
    "    for col in scaled_df.columns:\n",
    "        if scaled_df[col].dtype != 'object':\n",
    "            min_val = scaled_df[col].min()\n",
    "            max_val = scaled_df[col].max()\n",
    "            scaled_df[col] = (scaled_df[col] - min_val) / (max_val - min_val)\n",
    "    return scaled_df\n",
    "\n",
    "def remove_outliers_iqr(df):\n",
    "    df_clean = df.copy()\n",
    "    for col in df_clean.columns:\n",
    "        if df_clean[col].dtype != 'object':\n",
    "            Q1 = df_clean[col].quantile(0.25)\n",
    "            Q3 = df_clean[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower = Q1 - 1.5 * IQR\n",
    "            upper = Q3 + 1.5 * IQR\n",
    "            df_clean = df_clean[(df_clean[col] >= lower) & (df_clean[col] <= upper)]\n",
    "    return df_clean\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "def r2_score(y_true, y_pred):\n",
    "    ss_res = np.sum((y_true - y_pred) ** 2)\n",
    "    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "    return 1 - (ss_res / ss_tot)\n",
    "\n",
    "# Gradient Descent Implementation\n",
    "def gradient_descent(X, y, lr=0.01, epochs=1000):\n",
    "    m, n = X.shape\n",
    "    theta = np.zeros(n)\n",
    "    for _ in range(epochs):\n",
    "        preds = X.dot(theta)\n",
    "        error = preds - y\n",
    "        theta -= lr * (1/m) * X.T.dot(error)\n",
    "    return theta\n",
    "\n",
    "def predict(X, theta):\n",
    "    return X.dot(theta)\n",
    "\n",
    "# =========================\n",
    "#  HOUSING DATASET\n",
    "# =========================\n",
    "housing = pd.read_csv(r\"C:\\Users\\LENOVO\\Downloads\\Housing.csv\") \n",
    "\n",
    "# Drop categorical variables for simple regression\n",
    "housing = housing.select_dtypes(include=[np.number])\n",
    "\n",
    "housing = handle_missing_mean(housing)\n",
    "housing_scaled = min_max_scale(housing)\n",
    "\n",
    "# Split features & target\n",
    "X = housing_scaled.drop(columns=[\"price\"]).values\n",
    "y = housing_scaled[\"price\"].values\n",
    "X = np.c_[np.ones(X.shape[0]), X]  # bias term\n",
    "\n",
    "# Train before removing outliers\n",
    "theta_before = gradient_descent(X, y, lr=0.1, epochs=2000)\n",
    "y_pred_before = predict(X, theta_before)\n",
    "\n",
    "print(\"Before Outlier Removal -> MSE:\", mse(y, y_pred_before), \"R²:\", r2_score(y, y_pred_before))\n",
    "\n",
    "# Remove outliers\n",
    "housing_no_outliers = remove_outliers_iqr(housing_scaled)\n",
    "\n",
    "# Re-split\n",
    "X_no = housing_no_outliers.drop(columns=[\"price\"]).values\n",
    "y_no = housing_no_outliers[\"price\"].values\n",
    "X_no = np.c_[np.ones(X_no.shape[0]), X_no]\n",
    "\n",
    "theta_after = gradient_descent(X_no, y_no, lr=0.1, epochs=2000)\n",
    "y_pred_after = predict(X_no, theta_after)\n",
    "\n",
    "print(\"After Outlier Removal  -> MSE:\", mse(y_no, y_pred_after), \"R²:\", r2_score(y_no, y_pred_after))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99cbb46-c8b8-4983-aa1b-0ba91c0dd182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ee5304-07fe-45ac-ba01-d5cb93351838",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2b4371-52bd-4bee-9a39-042ee6a83825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "455b5799-204f-49f3-a234-61f234ee87ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows:\n",
      "       TV  Radio  Newspaper  Sales\n",
      "0  230.1   37.8       69.2   22.1\n",
      "1   44.5   39.3       45.1   10.4\n",
      "2   17.2   45.9       69.3   12.0\n",
      "3  151.5   41.3       58.5   16.5\n",
      "4  180.8   10.8       58.4   17.9\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   TV         200 non-null    float64\n",
      " 1   Radio      200 non-null    float64\n",
      " 2   Newspaper  200 non-null    float64\n",
      " 3   Sales      200 non-null    float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 6.4 KB\n",
      "None\n",
      "\n",
      "Before Outlier Removal -> MSE: 2.552028658496755 R²: 0.9114486959562746\n",
      "After Outlier Removal  -> MSE: 2.549316884744545 R²: 0.9219527784297882\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ------------------------\n",
    "# 1. Load the dataset\n",
    "# ------------------------\n",
    "df = pd.read_csv(r\"C:\\Users\\LENOVO\\Downloads\\advertising.csv\")  # Ensure CSV has 'TV', 'Radio', 'Newspaper', 'Sales'\n",
    "\n",
    "print(\"First 5 rows:\\n\", df.head())\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())\n",
    "\n",
    "# ------------------------\n",
    "# 2. Handle missing values (replace with mean)\n",
    "# ------------------------\n",
    "for col in df.columns:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        df[col].fillna(df[col].mean(), inplace=True)\n",
    "\n",
    "# ------------------------\n",
    "# 3. Min-Max Normalization (0-1 scaling)\n",
    "# ------------------------\n",
    "def min_max_scale(col):\n",
    "    return (col - col.min()) / (col.max() - col.min())\n",
    "\n",
    "df_scaled = df.copy()\n",
    "for col in df_scaled.columns[:-1]:  # Exclude target column 'Sales'\n",
    "    df_scaled[col] = min_max_scale(df_scaled[col])\n",
    "\n",
    "# ------------------------\n",
    "# Helper functions for Linear Regression from scratch\n",
    "# ------------------------\n",
    "def train_test_split(X, y, test_size=0.2):\n",
    "    idx = np.arange(len(X))\n",
    "    np.random.shuffle(idx)\n",
    "    split = int(len(X) * (1 - test_size))\n",
    "    return X[idx[:split]], X[idx[split:]], y[idx[:split]], y[idx[split:]]\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "def r2_score(y_true, y_pred):\n",
    "    ss_total = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "    ss_res = np.sum((y_true - y_pred) ** 2)\n",
    "    return 1 - (ss_res / ss_total)\n",
    "\n",
    "def gradient_descent(X, y, lr=0.01, epochs=1000):\n",
    "    m, n = X.shape\n",
    "    weights = np.zeros(n)\n",
    "    bias = 0\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        y_pred = np.dot(X, weights) + bias\n",
    "        dw = (-2/m) * np.dot(X.T, (y - y_pred))\n",
    "        db = (-2/m) * np.sum(y - y_pred)\n",
    "\n",
    "        weights -= lr * dw\n",
    "        bias -= lr * db\n",
    "\n",
    "    return weights, bias\n",
    "\n",
    "def predict(X, weights, bias):\n",
    "    return np.dot(X, weights) + bias\n",
    "\n",
    "# ------------------------\n",
    "# 4. Train before outlier removal\n",
    "# ------------------------\n",
    "X = df_scaled[['TV', 'Radio', 'Newspaper']].values\n",
    "y = df_scaled['Sales'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "weights, bias = gradient_descent(X_train, y_train, lr=0.01, epochs=5000)\n",
    "y_pred = predict(X_test, weights, bias)\n",
    "\n",
    "print(\"\\nBefore Outlier Removal -> MSE:\", mse(y_test, y_pred), \"R²:\", r2_score(y_test, y_pred))\n",
    "\n",
    "# ------------------------\n",
    "# 5. Detect and Remove Outliers using IQR\n",
    "# ------------------------\n",
    "def remove_outliers(df):\n",
    "    df_clean = df.copy()\n",
    "    for col in df_clean.columns[:-1]:  # Exclude target\n",
    "        Q1 = df_clean[col].quantile(0.25)\n",
    "        Q3 = df_clean[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - 1.5 * IQR\n",
    "        upper = Q3 + 1.5 * IQR\n",
    "        df_clean = df_clean[(df_clean[col] >= lower) & (df_clean[col] <= upper)]\n",
    "    return df_clean\n",
    "\n",
    "df_no_outliers = remove_outliers(df_scaled)\n",
    "\n",
    "# ------------------------\n",
    "# 6. Train after outlier removal\n",
    "# ------------------------\n",
    "X = df_no_outliers[['TV', 'Radio', 'Newspaper']].values\n",
    "y = df_no_outliers['Sales'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "weights, bias = gradient_descent(X_train, y_train, lr=0.01, epochs=5000)\n",
    "y_pred = predict(X_test, weights, bias)\n",
    "\n",
    "print(\"After Outlier Removal  -> MSE:\", mse(y_test, y_pred), \"R²:\", r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7999244a-6b63-4d32-aa20-6f5ddf07f5f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
